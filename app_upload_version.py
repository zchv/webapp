"""
CLIP Image Search - Enhanced Version with Better Semantic Search
ä¼˜åŒ–çš„è¯­ä¹‰æ£€ç´¢ç‰ˆæœ¬
"""

import streamlit as st
import torch
import open_clip
from PIL import Image
import numpy as np

# Page configuration
st.set_page_config(
    page_title="CLIP Image Search - Enhanced",
    page_icon="ğŸ”",
    layout="wide"
)

MODEL_NAME = 'ViT-B-32'
PRETRAINED = './models/ViT-B-32-laion2B-s34B-b79K/open_clip_pytorch_model.bin'

@st.cache_resource
def load_clip_model():
    """Load CLIP model"""
    device = "cuda" if torch.cuda.is_available() else "cpu"
    model, _, preprocess = open_clip.create_model_and_transforms(
        MODEL_NAME,
        pretrained=PRETRAINED
    )
    model = model.to(device)
    model.eval()
    tokenizer = open_clip.get_tokenizer(MODEL_NAME)
    return model, preprocess, tokenizer, device

# Initialize session state
if 'images' not in st.session_state:
    st.session_state.images = []
if 'image_features' not in st.session_state:
    st.session_state.image_features = None

def enhance_query(query):
    """å¢å¼ºæŸ¥è¯¢æ–‡æœ¬ï¼Œæé«˜è¯­ä¹‰æ£€ç´¢æ•ˆæœ"""
    query = query.strip()

    # å¦‚æœæŸ¥è¯¢å¾ˆçŸ­ï¼Œæ·»åŠ ä¸Šä¸‹æ–‡
    if len(query.split()) <= 2:
        # æ·»åŠ "a photo of"å‰ç¼€ï¼Œè¿™æ˜¯CLIPè®­ç»ƒæ—¶å¸¸ç”¨çš„æ¨¡å¼
        if not query.lower().startswith(('a ', 'an ', 'the ')):
            query = f"a photo of {query}"

    return query

def process_images(uploaded_files, model, preprocess, device):
    """Process uploaded images and extract features with better preprocessing"""
    images = []
    image_features_list = []

    progress_bar = st.progress(0)
    status_text = st.empty()

    for idx, uploaded_file in enumerate(uploaded_files):
        status_text.text(f"Processing {idx+1}/{len(uploaded_files)}: {uploaded_file.name}")

        try:
            # åŠ è½½å›¾åƒ
            image = Image.open(uploaded_file).convert("RGB")

            # ä¿å­˜åŸå§‹å›¾åƒç”¨äºæ˜¾ç¤º
            images.append((uploaded_file.name, image))

            # é¢„å¤„ç†å¹¶æå–ç‰¹å¾
            image_input = preprocess(image).unsqueeze(0).to(device)

            with torch.no_grad():
                # æå–å›¾åƒç‰¹å¾
                image_feature = model.encode_image(image_input)
                # L2å½’ä¸€åŒ– - è¿™å¯¹ä½™å¼¦ç›¸ä¼¼åº¦å¾ˆé‡è¦
                image_feature = image_feature / image_feature.norm(dim=-1, keepdim=True)

            image_features_list.append(image_feature)

        except Exception as e:
            st.warning(f"Error processing {uploaded_file.name}: {e}")
            continue

        progress_bar.progress((idx + 1) / len(uploaded_files))

    progress_bar.empty()
    status_text.empty()

    if image_features_list:
        image_features = torch.cat(image_features_list, dim=0)
        return images, image_features
    return [], None

def search_images(query, images, image_features, model, tokenizer, device, top_k=20,
                 use_query_enhancement=True, temperature=1.0):
    """
    Enhanced semantic search with multiple improvements

    Args:
        query: æœç´¢æŸ¥è¯¢
        images: å›¾åƒåˆ—è¡¨
        image_features: å›¾åƒç‰¹å¾
        model: CLIPæ¨¡å‹
        tokenizer: æ–‡æœ¬tokenizer
        device: è®¡ç®—è®¾å¤‡
        top_k: è¿”å›top kç»“æœ
        use_query_enhancement: æ˜¯å¦ä½¿ç”¨æŸ¥è¯¢å¢å¼º
        temperature: æ¸©åº¦å‚æ•°ï¼Œç”¨äºè°ƒæ•´ç›¸ä¼¼åº¦åˆ†å¸ƒ
    """
    # æŸ¥è¯¢å¢å¼º
    if use_query_enhancement:
        enhanced_query = enhance_query(query)
    else:
        enhanced_query = query

    # ç¼–ç æ–‡æœ¬
    text = tokenizer([enhanced_query]).to(device)

    with torch.no_grad():
        # æå–æ–‡æœ¬ç‰¹å¾
        text_features = model.encode_text(text)
        # L2å½’ä¸€åŒ–
        text_features = text_features / text_features.norm(dim=-1, keepdim=True)

    # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
    # image_features å’Œ text_features éƒ½å·²å½’ä¸€åŒ–ï¼Œæ‰€ä»¥ç‚¹ç§¯å°±æ˜¯ä½™å¼¦ç›¸ä¼¼åº¦
    similarity = (image_features @ text_features.T).squeeze()

    # åº”ç”¨æ¸©åº¦ç¼©æ”¾ï¼ˆå¯é€‰ï¼‰
    if temperature != 1.0:
        similarity = similarity / temperature

    # è½¬æ¢ä¸ºç™¾åˆ†æ¯” (0-100)
    similarity_percent = similarity * 100.0

    # æ’åºå¹¶è¿”å›top kç»“æœ
    if len(images) > 1:
        values, indices = similarity_percent.sort(descending=True)
        indices = indices[:top_k]
        results = [(images[idx], values[idx].item()) for idx in indices]
    else:
        results = [(images[0], similarity_percent.item())]

    return results, enhanced_query

# Main app
st.title("ğŸ” CLIP è¯­ä¹‰å›¾åƒæœç´¢ - å¢å¼ºç‰ˆ")
st.markdown("ä¸Šä¼ å›¾ç‰‡ï¼Œä½¿ç”¨è‡ªç„¶è¯­è¨€è¿›è¡Œè¯­ä¹‰æœç´¢ï¼")

# Load model
with st.spinner("Loading CLIP model..."):
    model, preprocess, tokenizer, device = load_clip_model()
st.success(f"âœ… Model loaded on {device}")

# Sidebar for image upload and settings
with st.sidebar:
    st.header("ğŸ“ Upload Images")
    uploaded_files = st.file_uploader(
        "Choose images",
        type=["jpg", "jpeg", "png", "webp", "bmp"],
        accept_multiple_files=True,
        key="file_uploader"
    )

    if uploaded_files:
        if st.button("Process Images", type="primary"):
            with st.spinner("Processing images..."):
                images, features = process_images(uploaded_files, model, preprocess, device)
                if images:
                    st.session_state.images = images
                    st.session_state.image_features = features
                    st.success(f"âœ… Processed {len(images)} images!")
                else:
                    st.error("No images were processed successfully")

    if st.session_state.images:
        st.markdown("---")
        st.metric("Images Loaded", len(st.session_state.images))

        if st.button("Clear All"):
            st.session_state.images = []
            st.session_state.image_features = None
            st.rerun()

    st.markdown("---")
    st.markdown("### âš™ï¸ Search Settings")

    use_enhancement = st.checkbox("Query Enhancement", value=True,
                                  help="è‡ªåŠ¨ä¼˜åŒ–æŸ¥è¯¢æ–‡æœ¬ä»¥æé«˜æ£€ç´¢æ•ˆæœ")

    temperature = st.slider("Temperature", min_value=0.1, max_value=2.0, value=1.0, step=0.1,
                           help="è°ƒæ•´ç›¸ä¼¼åº¦åˆ†å¸ƒã€‚<1: æ›´é›†ä¸­ï¼Œ>1: æ›´åˆ†æ•£")

    st.markdown("---")
    st.markdown("### â„¹ï¸ About")
    st.markdown(f"""
    **Model**: {MODEL_NAME} (LAION)
    **Device**: {device}
    **Features**:
    - Query enhancement
    - Temperature scaling
    - L2 normalized embeddings
    """)

# Main content
if st.session_state.images:
    st.subheader(f"ğŸ“Š {len(st.session_state.images)} images loaded")

    # Search interface
    col1, col2 = st.columns([4, 1])
    with col1:
        query = st.text_input(
            "ğŸ” Enter your search query",
            placeholder="ä¾‹å¦‚: ä¸€ä¸ªå¾®ç¬‘çš„äºº, red car, sunset, é£Ÿç‰©..."
        )
    with col2:
        top_k = st.number_input("Results", min_value=1, max_value=50,
                               value=min(20, len(st.session_state.images)))

    # æœç´¢æç¤º
    with st.expander("ğŸ’¡ æœç´¢æŠ€å·§"):
        st.markdown("""
        **æé«˜æ£€ç´¢æ•ˆæœçš„æŠ€å·§:**

        1. **ä½¿ç”¨æè¿°æ€§è¯­è¨€**:
           - âœ… "a person wearing red shirt smiling"
           - âŒ "person"

        2. **åŒ…å«å…³é”®ç‰¹å¾**:
           - âœ… "sunset over ocean with orange sky"
           - âŒ "sunset"

        3. **ä½¿ç”¨å…·ä½“è¯æ±‡**:
           - âœ… "golden retriever dog playing"
           - âŒ "animal"

        4. **æ”¯æŒä¸­è‹±æ–‡**:
           - "ä¸€åªå¯çˆ±çš„çŒ«å’ª"
           - "a cute cat"

        5. **ç»„åˆå¤šä¸ªæ¦‚å¿µ**:
           - "modern building with glass windows at night"
        """)

    if query:
        with st.spinner("Searching..."):
            results, enhanced_query = search_images(
                query,
                st.session_state.images,
                st.session_state.image_features,
                model,
                tokenizer,
                device,
                int(top_k),
                use_query_enhancement=use_enhancement,
                temperature=temperature
            )

        # æ˜¾ç¤ºå¢å¼ºåçš„æŸ¥è¯¢
        if use_enhancement and enhanced_query != query:
            st.info(f"ğŸ”„ Enhanced query: `{enhanced_query}`")

        st.markdown(f"### Results for: *'{query}'*")

        # æ˜¾ç¤ºç›¸ä¼¼åº¦ç»Ÿè®¡
        scores = [score for _, score in results]
        if scores:
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("Highest Score", f"{max(scores):.1f}%")
            with col2:
                st.metric("Average Score", f"{np.mean(scores):.1f}%")
            with col3:
                st.metric("Lowest Score", f"{min(scores):.1f}%")

        # Display results in grid
        cols_per_row = 4
        for i in range(0, len(results), cols_per_row):
            cols = st.columns(cols_per_row)
            for j, col in enumerate(cols):
                if i + j < len(results):
                    (name, image), score = results[i + j]
                    with col:
                        st.image(image, use_container_width=True)

                        # é¢œè‰²ç¼–ç ç›¸ä¼¼åº¦
                        if score >= 30:
                            color = "ğŸŸ¢"
                        elif score >= 20:
                            color = "ğŸŸ¡"
                        else:
                            color = "ğŸ”´"

                        st.caption(f"{color} **{score:.1f}%** - {name}")

    # Show all images
    with st.expander("ğŸ“¸ View all uploaded images"):
        cols = st.columns(5)
        for idx, (name, image) in enumerate(st.session_state.images):
            with cols[idx % 5]:
                st.image(image, caption=name, use_container_width=True)

else:
    st.info("ğŸ‘ˆ Please upload images using the sidebar to get started!")

    # Example queries
    st.markdown("### ğŸ’¡ Example Queries")

    col1, col2 = st.columns(2)

    with col1:
        st.markdown("**English:**")
        st.markdown("""
        - "a person smiling happily"
        - "red sports car on street"
        - "delicious food on white plate"
        - "beautiful sunset over mountains"
        - "modern office interior"
        - "cute dog playing in park"
        """)

    with col2:
        st.markdown("**ä¸­æ–‡:**")
        st.markdown("""
        - "ä¸€ä¸ªå¼€å¿ƒå¾®ç¬‘çš„äºº"
        - "è¡—é“ä¸Šçš„çº¢è‰²è·‘è½¦"
        - "ç™½è‰²ç›˜å­ä¸Šçš„ç¾é£Ÿ"
        - "å±±ä¸Šçš„ç¾ä¸½æ—¥è½"
        - "ç°ä»£åŠå…¬å®¤å†…æ™¯"
        - "å…¬å›­é‡Œç©è€çš„å¯çˆ±å°ç‹—"
        """)

    st.markdown("### ğŸš€ Quick Start")
    st.markdown("""
    1. Click **"Browse files"** in the sidebar
    2. Select multiple images from your computer
    3. Click **"Process Images"**
    4. Enter a natural language query to search
    5. Adjust settings for better results
    """)

    st.markdown("### ğŸ¯ ä¼˜åŒ–å»ºè®®")
    st.markdown("""
    - **Query Enhancement**: è‡ªåŠ¨æ·»åŠ "a photo of"ç­‰å‰ç¼€ï¼Œæé«˜æ£€ç´¢å‡†ç¡®åº¦
    - **Temperature**: è°ƒæ•´ç›¸ä¼¼åº¦åˆ†å¸ƒï¼Œæ‰¾åˆ°æœ€é€‚åˆä½ æ•°æ®çš„è®¾ç½®
    - **æè¿°æ€§æŸ¥è¯¢**: ä½¿ç”¨æ›´è¯¦ç»†çš„æè¿°è¯è·å¾—æ›´å¥½çš„ç»“æœ
    """)
