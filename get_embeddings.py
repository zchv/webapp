"""
ç”Ÿæˆå›¾ç‰‡å‘é‡å¹¶ä¿å­˜ä¸ºpklæ–‡ä»¶
ç”¨æ³•: python get_embeddings.py
"""

import torch
import open_clip
from PIL import Image
import os
import pickle
from tqdm import tqdm
import numpy as np

# é…ç½®
IMAGE_FOLDER = "./data/images"
OUTPUT_FILE = "image_embeddings.pkl"
MODEL_NAME = 'ViT-B-32'
PRETRAINED = './models/ViT-B-32-laion2B-s34B-b79K/open_clip_pytorch_model.bin'

def get_image_files(folder):
    """è·å–æ–‡ä»¶å¤¹ä¸­æ‰€æœ‰å›¾ç‰‡æ–‡ä»¶"""
    extensions = {'.jpg', '.jpeg', '.png', '.webp', '.bmp', '.gif'}
    image_files = []

    for root, dirs, files in os.walk(folder):
        for file in files:
            if os.path.splitext(file.lower())[1] in extensions:
                image_files.append(os.path.join(root, file))

    return sorted(image_files)

def generate_embeddings():
    """ä¸ºæ‰€æœ‰å›¾ç‰‡ç”Ÿæˆembeddings"""
    print(f"ğŸ”§ åŠ è½½CLIPæ¨¡å‹: {MODEL_NAME}")
    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"ğŸ“± ä½¿ç”¨è®¾å¤‡: {device}")

    # åŠ è½½æ¨¡å‹
    model, _, preprocess = open_clip.create_model_and_transforms(
        MODEL_NAME,
        pretrained=PRETRAINED
    )
    model = model.to(device)
    model.eval()

    print(f"\nğŸ“‚ æ‰«æå›¾ç‰‡æ–‡ä»¶å¤¹: {IMAGE_FOLDER}")
    image_files = get_image_files(IMAGE_FOLDER)

    if not image_files:
        print(f"âŒ åœ¨ {IMAGE_FOLDER} ä¸­æ²¡æœ‰æ‰¾åˆ°å›¾ç‰‡")
        print(f"è¯·å°†å›¾ç‰‡æ”¾å…¥è¯¥æ–‡ä»¶å¤¹åé‡è¯•")
        return

    print(f"âœ… æ‰¾åˆ° {len(image_files)} å¼ å›¾ç‰‡")

    # ç”Ÿæˆembeddings
    embeddings = []
    valid_files = []

    print("\nğŸ”„ ç”Ÿæˆembeddings...")
    with torch.no_grad():
        for img_path in tqdm(image_files, desc="å¤„ç†è¿›åº¦"):
            try:
                # åŠ è½½å¹¶é¢„å¤„ç†å›¾ç‰‡
                image = Image.open(img_path).convert('RGB')
                image_input = preprocess(image).unsqueeze(0).to(device)

                # ç”Ÿæˆembedding
                image_features = model.encode_image(image_input)
                # L2å½’ä¸€åŒ–
                image_features = image_features / image_features.norm(dim=-1, keepdim=True)

                embeddings.append(image_features.cpu().numpy())
                valid_files.append(img_path)

            except Exception as e:
                print(f"\nâš ï¸  å¤„ç† {img_path} æ—¶å‡ºé”™: {e}")
                continue

    if not embeddings:
        print("âŒ æ²¡æœ‰æˆåŠŸç”Ÿæˆä»»ä½•embeddings")
        return

    # åˆå¹¶embeddings
    embeddings = np.vstack(embeddings)

    # ä¿å­˜åˆ°pickleæ–‡ä»¶
    data = {
        'embeddings': embeddings,
        'image_paths': valid_files,
        'model_name': MODEL_NAME,
        'pretrained': PRETRAINED
    }

    print(f"\nğŸ’¾ ä¿å­˜embeddingsåˆ° {OUTPUT_FILE}")
    with open(OUTPUT_FILE, 'wb') as f:
        pickle.dump(data, f)

    print(f"âœ… æˆåŠŸä¸º {len(valid_files)} å¼ å›¾ç‰‡ç”Ÿæˆembeddings")
    print(f"ğŸ“¦ Embeddingç»´åº¦: {embeddings.shape}")
    print(f"ğŸ’¾ å·²ä¿å­˜åˆ°: {OUTPUT_FILE}")
    print(f"\nğŸš€ ç°åœ¨å¯ä»¥è¿è¡Œ python build_faiss_index.py æ¥æ„å»ºFAISSç´¢å¼•")

if __name__ == "__main__":
    generate_embeddings()
